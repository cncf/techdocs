# New CNCF tech doc artifacts

## Existing

How-to
Template
Criteria

1. Revise template to match what I've done
2. Explain how to build out the umbrella and sub-issues
3. Create another folder for the process

## Artifacts:
README: preamble, theory, objectives, audience, lay out the program. Then link to:

How-to: checklist or recipe. CNCF requirements -- what does Nate need?

Template: update.

Criteria: how do you evaluate?

Scoring/ranking - purposes:
- Appearance of objectivity
- Maturity level of software
- Shame maintainers into taking doc seriously
- Expected

Scoring: needed or not?

| Reason | Importance | Notes |
| --- | --- | --- |
| Objectivity |  | Gives at least the appearance of an objective evaluation (that's why I started using the term "rubric", btw) |
| Objectivity, appearance of |  | Gives at least the appearance of an objective evaluation (that's why I started using the term "rubric", btw) |
| Shame maintainers |  |  |
| Match software maturity |  | Agree that for incubating and graduated projects |
| Expected |  | Quantitative analysis vs. Qualitative? |
|  |  |  |

Evaluate on effort vs impact?

Documentation for Developers

## Audiences:
1. Maintainers - what's in it for me?
2. Analyst - doing the analysis work - what is "done"?
3. Foundation (CNCF) - keep the customer satisfied - should address expectation.
4. Foundation (other) - want to be able to use as a model for other orgs.
5. Contributors - writers who pick up the work -- need to define what we expect of these people.

## Repo Outline

- **cncf-techdocs**
  - **docs**: Documentation 
  - 